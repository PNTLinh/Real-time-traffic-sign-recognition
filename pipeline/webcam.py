import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
os.environ["OMP_NUM_THREADS"] = "1"

import cv2
import supervision as sv
from ultralytics import YOLO
import time

# ==== C·∫§U H√åNH ====
MODEL_PATH = r"C:\Users\Admin\OneDrive\Desktop\deeplearning_project\Real-time-traffic-sign-recognition\weights\yolo\best.onnx"
IMG_SIZE = 1024
CONF_THRESH = 0.2
FRAME_SKIP = 3
SAVE_OUTPUT = True
OUTPUT_PATH = "webcam_output.mp4"
OUTPUT_FPS = 25 # Target FPS for the output video
# --- Th√™m c·∫•u h√¨nh ƒë·ªô ph√¢n gi·∫£i webcam ---
# Y√™u c·∫ßu webcam m·ªü ·ªü 1280x720 (HD)
WEBCAM_WIDTH = 1280
WEBCAM_HEIGHT = 720
# ------------------------------------------


# ==== LOAD MODEL ====
print("üîπ ƒêang t·∫£i model ONNX...")
# Ensure you have the correct ONNX provider installed (e.g., onnxruntime or onnxruntime-gpu)
model = YOLO(MODEL_PATH, task="detect")
tracker = sv.ByteTrack()
box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

# ==== M·ªû WEBCAM ====
cap = cv2.VideoCapture(0) # Use 0 for default webcam
if not cap.isOpened():
    raise Exception("‚ùå Kh√¥ng th·ªÉ m·ªü webcam! Ki·ªÉm tra xem webcam c√≥ ƒë∆∞·ª£c k·∫øt n·ªëi kh√¥ng.")

# --- ƒê·∫∑t ƒë·ªô ph√¢n gi·∫£i mong mu·ªën ---
cap.set(cv2.CAP_PROP_FRAME_WIDTH, WEBCAM_WIDTH)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, WEBCAM_HEIGHT)
# -----------------------------------

w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Set FPS tren webcam
webcam_fps = cap.get(cv2.CAP_PROP_FPS)
if webcam_fps <= 0:
    print("‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y FPS t·ª´ webcam, m·∫∑c ƒë·ªãnh l√† 30.")
    webcam_fps = 30

print(f"üé• Webcam m·ªü th√†nh c√¥ng: {w}x{h} @ {webcam_fps:.2f} FPS")


if SAVE_OUTPUT:
    # Use OUTPUT_FPS for the writer, as this is the target saved FPS
    out = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'mp4v'), OUTPUT_FPS, (w, h))
    if not out.isOpened():
        print(f"‚ùå Kh√¥ng th·ªÉ t·∫°o file video t·∫°i: {OUTPUT_PATH}")
        SAVE_OUTPUT = False # Disable saving if it fails
    else:
        print(f"üíæ K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i: {OUTPUT_PATH}")

print("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω... Nh·∫•n 'q' tr√™n c·ª≠a s·ªï video ƒë·ªÉ tho√°t.")

# --- TH√äM D√íNG N√ÄY ƒê·ªÇ CHO PH√âP RESIZE C·ª¨A S·ªî ---
WINDOW_NAME = "üîç YOLO ONNX + Supervision (Webcam)"
cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)
# ----------------------------------------------

frame_count = 0
frame_processed = 0
last_display_time = time.time()
processing_fps = 0

# ==== V√íNG L·∫∂P CH√çNH ====
try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c khung h√¨nh t·ª´ webcam. K·∫øt th√∫c.")
            break

        frame_count += 1
        
        # B·ªè qua frame n·∫øu FRAME_SKIP > 1
        if frame_count % FRAME_SKIP != 0:
            continue

        start_time = time.time() # B·∫Øt ƒë·∫ßu ƒë·∫øm th·ªùi gian x·ª≠ l√Ω

        # === D·ª∞ ƒêO√ÅN ===
        # verbose=False ƒë·ªÉ t·∫Øt log c·ªßa YOLO cho m·ªói frame
        results = model(frame, imgsz=IMG_SIZE, conf=CONF_THRESH, verbose=False)[0]
        detections = sv.Detections.from_ultralytics(results)
        
        # === TRACKING ===
        # Ch·ªâ update tracker n·∫øu c√≥ detections
        if len(detections) > 0:
            tracked = tracker.update_with_detections(detections)
        else:
            # N·∫øu kh√¥ng c√≥ g√¨, g·ªçi update r·ªóng ƒë·ªÉ tracker c√≥ th·ªÉ x·ª≠ l√Ω c√°c track c≈©
            tracked = tracker.update_with_detections(sv.Detections.empty())


        # === V·∫º LABEL & BOX ===
        annotated_frame = frame.copy() # Lu√¥n b·∫Øt ƒë·∫ßu t·ª´ frame g·ªëc
        
        if len(tracked) > 0:
            # L·∫•y th√¥ng tin t·ª´ results.names
            labels = [
                f"{model.names[int(c)]} {conf:.2f}"
                for c, conf in zip(tracked.class_id, tracked.confidence)
            ]

            # 1. V·∫Ω boxes
            annotated_frame = box_annotator.annotate(
                scene=annotated_frame,
                detections=tracked
                # X√≥a 'labels=labels' kh·ªèi ƒë√¢y
            )
            # 2. V·∫Ω labels
            annotated_frame = label_annotator.annotate(
                scene=annotated_frame,
                detections=tracked,
                labels=labels
            )
        
        # === T√çNH TO√ÅN & HI·ªÇN TH·ªä FPS ===
        # T√≠nh FPS d·ª±a tr√™n th·ªùi gian x·ª≠ l√Ω th·ª±c t·∫ø
        end_time = time.time()
        processing_time = end_time - start_time
        
        # Tr√°nh chia cho 0 n·∫øu x·ª≠ l√Ω qu√° nhanh
        if processing_time > 0:
            # T√≠nh FPS c·ªßa ri√™ng ph·∫ßn x·ª≠ l√Ω (model + drawing)
            # Nh√¢n v·ªõi FRAME_SKIP ƒë·ªÉ ∆∞·ªõc t√≠nh FPS n·∫øu x·ª≠ l√Ω m·ªçi frame
            processing_fps = (1.0 / processing_time) 

        cv2.putText(annotated_frame, f"Proc FPS: {processing_fps:.1f}", (10, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.putText(annotated_frame, f"Skipping: {FRAME_SKIP-1} frames", (10, 80), # <-- S·ª¨A L·ªñI ·ªû ƒê√ÇY (t·ª´ annot2 th√†nh annotated_frame)
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)


        # === HI·ªÇN TH·ªä & GHI ===
        cv2.imshow(WINDOW_NAME, annotated_frame) # ƒê·∫£m b·∫£o t√™n c·ª≠a s·ªï kh·ªõp
        
        if SAVE_OUTPUT and out.isOpened():
            out.write(annotated_frame)

        frame_processed += 1
        
        # Ph√≠m tho√°t
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("\nüõë Ng∆∞·ªùi d√πng nh·∫•n 'q', ƒëang tho√°t...")
            break
except KeyboardInterrupt:
    print("\nüõë ƒê√£ ph√°t hi·ªán KeyboardInterrupt, ƒëang d·ª´ng...")

# ==== D·ªåN D·∫∏P ====
print(f"\n‚úÖ Ho√†n t·∫•t! ƒê√£ x·ª≠ l√Ω t·ªïng c·ªông {frame_processed} frame.")
cap.release()
print("üîå Webcam ƒë√£ ƒë∆∞·ª£c gi·∫£i ph√≥ng.")
if SAVE_OUTPUT and out.isOpened():
    out.release()
    print(f"üíæ File video ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {OUTPUT_PATH}")
cv2.destroyAllWindows()
print("Cleanup complete.")


